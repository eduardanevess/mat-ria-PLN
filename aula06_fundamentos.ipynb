{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuYeUgUA030MU/FosXzbmh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduardanevess/materia-PLN/blob/master/aula06_fundamentos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aula 6 - Representação de Texto com Embeddings"
      ],
      "metadata": {
        "id": "39UztMrkm2zg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 1 - Word2Vex"
      ],
      "metadata": {
        "id": "CspXqjg4m6IN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "390Y_gJnmHwr",
        "outputId": "6f2942ad-db61-4b57-92f5-d944f9c9cb9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-8.7274825e-03  2.1301615e-03 -8.7354420e-04 -9.3190884e-03\n",
            " -9.4281426e-03 -1.4107180e-03  4.4324086e-03  3.7040710e-03\n",
            " -6.4986930e-03 -6.8730675e-03 -4.9994122e-03 -2.2868442e-03\n",
            " -7.2502876e-03 -9.6033178e-03 -2.7436293e-03 -8.3628409e-03\n",
            " -6.0388758e-03 -5.6709289e-03 -2.3441375e-03 -1.7069972e-03\n",
            " -8.9569986e-03 -7.3519943e-04  8.1525063e-03  7.6904297e-03\n",
            " -7.2061159e-03 -3.6668312e-03  3.1185520e-03 -9.5707225e-03\n",
            "  1.4764392e-03  6.5244664e-03  5.7464195e-03 -8.7630618e-03\n",
            " -4.5171441e-03 -8.1401607e-03  4.5956374e-05  9.2636338e-03\n",
            "  5.9733056e-03  5.0673080e-03  5.0610625e-03 -3.2429171e-03\n",
            "  9.5521836e-03 -7.3564244e-03 -7.2703874e-03 -2.2653891e-03\n",
            " -7.7856064e-04 -3.2161034e-03 -5.9258583e-04  7.4888230e-03\n",
            " -6.9751858e-04 -1.6249407e-03  2.7443992e-03 -8.3591007e-03\n",
            "  7.8558037e-03  8.5361041e-03 -9.5840869e-03  2.4462664e-03\n",
            "  9.9049713e-03 -7.6658037e-03 -6.9669187e-03 -7.7365171e-03\n",
            "  8.3959233e-03 -6.8133592e-04  9.1444086e-03 -8.1582209e-03\n",
            "  3.7430846e-03  2.6350426e-03  7.4271322e-04  2.3276759e-03\n",
            " -7.4690939e-03 -9.3583735e-03  2.3545765e-03  6.1484552e-03\n",
            "  7.9856887e-03  5.7358947e-03 -7.7733636e-04  8.3061643e-03\n",
            " -9.3363142e-03  3.4061326e-03  2.6675343e-04  3.8572443e-03\n",
            "  7.3857834e-03 -6.7251669e-03  5.5844807e-03 -9.5222248e-03\n",
            " -8.0445886e-04 -8.6887367e-03 -5.0986730e-03  9.2892265e-03\n",
            " -1.8582619e-03  2.9144264e-03  9.0712793e-03  8.9381328e-03\n",
            " -8.2084350e-03 -3.0123137e-03  9.8866057e-03  5.1044310e-03\n",
            " -1.5880871e-03 -8.6920215e-03  2.9615164e-03 -6.6758976e-03]\n",
            "Similaridade entre 'cachorro' e 'gato':  0.13149002\n"
          ]
        }
      ],
      "source": [
        "# Importação da ferramenta de vetorização\n",
        "# Modelo de vetorização foi criado pelo Google em 2013\n",
        "from gensim.models import Word2Vec\n",
        "# Pesquisa biblioteca na documentação\n",
        "\n",
        "# Texto a ser analisado\n",
        "corpus = [\n",
        "    [\"o\",\"cachorro\",\"está\",\"latindo\"],\n",
        "    [\"o\",\"gato\",\"está\",\"miando\"]\n",
        "]\n",
        "\n",
        "# Realizar o treinamento das palavras\n",
        "model = Word2Vec(sentences=corpus, vector_size=100, window=5, min_count=1, sg=1)\n",
        "# setences >>> indicar o texto a ser analisado.\n",
        "# window >>> faixa de palavras (antes e depois) que serão analisadoas\n",
        "# vector_size >>> Dimensão do vetor\n",
        "# min_count=1\n",
        "# sg >>> representa o modelo a ser utilizado\n",
        "# 0 >>> CBOW: busca a palavra a partir do contexto\n",
        "# 1 >>> Skip-gram: busco o contexto a partir da palavra\n",
        "\n",
        "# Vetorização da palavra desejada\n",
        "vector = model.wv['cachorro']\n",
        "print(vector) # Changed 'vetor' to 'vector'\n",
        "\n",
        "# Comparação de vetores.\n",
        "similarity = model.wv.similarity('gato','cachorro')\n",
        "\n",
        "# Imprimir o resultado\n",
        "print(\"Similaridade entre 'cachorro' e 'gato': \",similarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 2"
      ],
      "metadata": {
        "id": "xN-65DSpnAk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "corpus = [\n",
        "    [\"o\", \"cachorro\", \"está\", \"latindo\", \"no\", \"quintal\"],\n",
        "    [\"o\", \"gato\", \"está\", \"miando\", \"no\", \"telhado\"],\n",
        "    [\"o\", \"pássaro\", \"está\", \"voando\", \"no\", \"céu\"],\n",
        "    [\"a\", \"bola\", \"está\", \"rolando\", \"no\", \"chão\"],\n",
        "    [\"a\", \"criança\", \"está\", \"brincando\", \"com\", \"o\", \"cachorro\"],\n",
        "    [\"o\", \"gato\", \"e\", \"o\", \"rato\", \"são\", \"inimigos\"],\n",
        "    [\"a\", \"água\", \"está\", \"quente\", \"na\", \"caneca\"],\n",
        "    [\"o\", \"sol\", \"está\", \"brilhando\", \"no\", \"céu\"],\n",
        "    [\"a\", \"lua\", \"está\", \"cheia\", \"hoje\"],\n",
        "    [\"a\", \"computador\", \"está\", \"ligado\", \"na\", \"mesa\"]\n",
        "]\n",
        "\n",
        "model = Word2Vec(sentences=corpus, vector_size=100, window=5, min_count=1, sg=1)\n",
        "\n",
        "# Calculando a similaridade entre palavras\n",
        "print(f\"Similidaridade entre cachorro e gato: {model.wv.similarity('cachorro', 'gato')}\")\n",
        "print(f\"Similidaridade entre cachorro e bola: {model.wv.similarity('cachorro', 'bola')}\")\n",
        "print(f\"Similidaridade entre céu e lua: {model.wv.similarity('céu', 'lua')}\")\n",
        "print(f\"Similidaridade entre computador e mesa: {model.wv.similarity('computador', 'mesa')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_J4KyoknBc7",
        "outputId": "3944eed0-a113-4dbc-eddf-ad07f7bce9c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similidaridade entre cachorro e gato: -0.027537165209650993\n",
            "Similidaridade entre cachorro e bola: 0.08071544766426086\n",
            "Similidaridade entre céu e lua: 0.16293543577194214\n",
            "Similidaridade entre computador e mesa: 0.037479717284440994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 3 - Glove\n",
        "\n",
        "Neste exemplo será necessário baixar o arquivo de referência do site oficial do projeto GloVe, no repositório da Stanford NLP, acessível pelo link [repositório da Stanford NLP link](https://nlp.stanford.edu/projects/glove/)\n",
        "* Na página, procure pela seção \"Pre-trained word vectors\" e escolha o conjunto Common Crawl (glove.6B). O download incluirá vários arquivos em um arquivo compactado (.zip), com opções de vetores de 50, 100, 200 e 300 dimensões.\n",
        "\n",
        "Passos para usar o glove.6B.100d.txt\n",
        "1. Baixeo arquivo e extraia o conteúdo;\n",
        "2. Escolha a dimensão desejada (O glove.6B.100d.txt representa embeddings com 100 dimensões, um bom equilíbrio entre precisão e eficiência);\n",
        "3. Para carregar o arquivo no Python usanod Gensim, como no exemplo anterior, especifique o caminho para glove.6B.100d.txt após a extração.\n",
        "\n",
        "Para carregar o arquivo salvo no Google Drive no Google Colab siga os passos abaixo:\n",
        "1. Monte o Google Drive no Colab\n",
        "2. Localize o caminho do Arquivo\n",
        "3. Carregue o Arquivo no Python usando o caminho completo\n",
        "\n",
        "> glove_path = '/content/drive/MyDrive/embeddings/glove.6B.100d.txt'\n"
      ],
      "metadata": {
        "id": "lqD4xBranF5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação da biblioteca\n",
        "from gensim.models import KeyedVectors\n",
        "import os\n",
        "\n",
        "# Indicação do caminho do arquivo\n",
        "glove_path = '/content/glove.6B.100d.txt'\n",
        "\n",
        "# Download the file if it doesn't exist\n",
        "if not os.path.exists(glove_path):\n",
        "    !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "    !unzip glove.6B.zip\n",
        "    # Remove the zip file to save space\n",
        "    !rm glove.6B.zip\n",
        "\n",
        "\n",
        "# Acesso ao modelo treinado (instanciação)\n",
        "glove_model = KeyedVectors.load_word2vec_format(glove_path, binary=False, no_header=True)\n",
        "  # glove_path >>> caminho do arquivo com o modelo treinado\n",
        "  # binary >>> arquivo em texto (False)\n",
        "  # no_header >>> ignorar o cabeçalho\n",
        "\n",
        "# Método para acessar a similaridade de duas palavras dentro do modelo treinado\n",
        "similaridade = glove_model.similarity('king', 'queen')\n",
        "print(\"Similaridade entre 'king' e 'queen': \", similaridade)\n",
        "\n",
        "# Método de proximidade para uma determinada palavra \"King\"\n",
        "palavras_proximas = glove_model.most_similar('king')\n",
        "print(\"Palavras próximas a 'king': \", palavras_proximas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSB6Kje0nHyL",
        "outputId": "57c3c4d8-da26-4cda-808c-545fa80484b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similaridade entre 'king' e 'queen':  0.7507691\n",
            "Palavras próximas a 'king':  [('prince', 0.7682328820228577), ('queen', 0.7507690787315369), ('son', 0.7020888328552246), ('brother', 0.6985775232315063), ('monarch', 0.6977890729904175), ('throne', 0.6919989585876465), ('kingdom', 0.6811409592628479), ('father', 0.6802029013633728), ('emperor', 0.6712858080863953), ('ii', 0.6676074266433716)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 4 - FastText\n",
        "\n",
        "Baixar o modelo FastText pré-treinados em português diretamente do site da Meta AI [Facebook AI](https://fasttext.cc/docs/en/crawl-vectors.html)\n",
        "1. Role para baixo até seção \"Download pre-trained word vectors\" e procure o idioma português;\n",
        "2. O modelo em português é chamado cc.pt.300.vec (em formato de texto) ou cc.pt.300.bin (em formato binário);\n",
        "3. Clique para baixar o modelo desejado;\n",
        "4. Carregue o modelo no Google Drive."
      ],
      "metadata": {
        "id": "F3xlnaHLnLu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das funcionalidades\n",
        "from gensim.models import fasttext\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Indicação do caminho do arquivo\n",
        "fasttext_path = '/content/drive/MyDrive/[FATEC] PLN/cc.pt.300.vec'\n",
        "\n",
        "# Instanciação do objeto\n",
        "fasttext_model = KeyedVectors.load_word2vec_format(fasttext_path, binary=False, no_header=True)\n",
        "\n",
        "# Cálculo de proximidade\n",
        "similaridade = fasttext_model.similarity('gato', 'gatinhos')\n",
        "print(f\"Similaridade entre 'gato' e 'gatinhos': {similaridade:.4f}\")\n",
        "\n",
        "# Cálculo das palavras mais próximas\n",
        "palavras_proximas = fasttext_model.most_similar('gato')\n",
        "print(\"Palavras mais próximas de 'gato': \")\n",
        "for palavra, score in palavras_proximas:\n",
        "  print(f\"{palavra}: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "zIKt1hg-nOSv",
        "outputId": "df7ed3bf-d8b8-45c3-f6f6-db9246ae1a05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/[FATEC] PLN/cc.pt.300.vec'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2e8de6a4f6c4>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Instanciação do objeto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfasttext_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasttext_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Cálculo de proximidade\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m         \"\"\"\n\u001b[0;32m-> 1719\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1720\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[0;31m# deduce both vocab_size & vector_size from 1st pass over file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/[FATEC] PLN/cc.pt.300.vec'"
          ]
        }
      ]
    }
  ]
}